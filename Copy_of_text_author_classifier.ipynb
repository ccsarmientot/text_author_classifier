{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv7xZ-Vm2LLw"
      },
      "source": [
        "### 0. Libraries and utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8KukHBS2LL0",
        "outputId": "956454a7-7f27-441a-b7be-c708087dc652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFSXIJGW2LL3",
        "outputId": "0e4c6f9d-3394-481f-d619-8aa2bfdcc849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'say love place'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove accents\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Remove English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "    # Join the tokens back into a single string\n",
        "    text = ' '.join(tokens)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Limpiamos el texto\n",
        "preprocess_text('What can I say, I love this place')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40IR3mA-2LL5"
      },
      "source": [
        "### 1. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loeywsa-2LL6",
        "outputId": "0f616d58-9b62-45bb-b370-935ecd1f3716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataframe: (10000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  author\n",
              "28172  now when nobody else was to be had and no high...      26\n",
              "4098   said to me john you was always honorable and i...       8\n",
              "21493  not see the lady s face until the marriage day...      20\n",
              "16864  so you have come at last yes here i am and how...      15\n",
              "2727   night what jack you be a soldier yes if you th...       4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25d084e7-a273-419e-a9a2-f868d277bb3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28172</th>\n",
              "      <td>now when nobody else was to be had and no high...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4098</th>\n",
              "      <td>said to me john you was always honorable and i...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21493</th>\n",
              "      <td>not see the lady s face until the marriage day...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16864</th>\n",
              "      <td>so you have come at last yes here i am and how...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>night what jack you be a soldier yes if you th...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d084e7-a273-419e-a9a2-f868d277bb3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25d084e7-a273-419e-a9a2-f868d277bb3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25d084e7-a273-419e-a9a2-f868d277bb3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1314b5f2-0890-4aec-a3eb-de7bc4afa760\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1314b5f2-0890-4aec-a3eb-de7bc4afa760')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1314b5f2-0890-4aec-a3eb-de7bc4afa760 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"the united states and to to make all rule and te the preservation management and sale of the same the provision to temporary for uie new states arising in the lands of the united states taken in c with the one em to exclusively authority at the seat of the government and over a district of country the same clearly shows the difference in the extent and na ture of the powers intended to be conferred in the states or on the one hand and in the district of on the other in the one case it was pro posed to to temporary for the new or as they are now called just as our fathers recognised the right of the british crown to local govern ments for the colonies by issuing under which the people of the colonies were entitled according to the bill of nights adopted by the continental to a fr ee and exclusive power of in their provincial where their ri t of representation can alone be preserved in all cases of and in the other case it was proposed to to exercise authority over the and of the people within the district which should be for that purpose as the seat of the general government each of these provisions was modified and by the committee of detail and as will appear by comparing them with the corresponding as finally into the constitution the provision to to temporary for the new states or and to provide for their into the union appears in the la this form new states may be admitted by the into this union the power to admit h and to make all laws which shall be and proper to that end may fairly be to include the right to temporary for such new states or the same as great britain could similar for the colonies but not to to m respect to affairs and internal concerns that great principle in of which the battles of the revolution were fought if authority were deemed necessary to give force to principles so eminently just in themselves and which form the basis of our entire political system such authority may be found in the opinion of the court of the united states hi the scott case in that case the court say this brings us to examine by what provision of the the present l under its and powers is to territory outside original of the united and what powers it may exercise therein over the or property or a sen of the united while it remains a and until it shall be admitted as one of the there is certainly no power given by the constitution to the government to or maintain colonies on the united states or at a distance to be rum and governed at its own pleasure nor to e lu limits in any way except by the of new states the power to the territory of the united by the of new states is plainly given and in the of this power by all the of the it has been held to the acquisition of territory not for admission at the time but to be ki as as population and situation it to it is acquired to become a state and not to be held as a colony and governed by with authority and as the propriety of admitting a new is to tho sound discretion of the power to acquire territory br that purpose to be held by the united it is in a condition to become a state upon an equal with other states must rest upon the discretion having determined the question that uie i to territory for the purpose of our limits and increasing the number of state is included within the power to admit new states and conferred by the same of the uie court proceed to say that the power to necessarily s with it the power to preserve and apply to the \\u00e2 i for it was acquired and again to a former decision of the same court in respect to the ut to for the the court say the stands firmly on tlie latter put by on popular s that g ma the inevitable of the right to territory the power to acquire territory as well aa the right in the language of mr to temporary for the new states arising therein or as they are now called having been to that of the constitution wliich for the of new states the court proceed to consider the nature and extent of the power of over the people of the all wc mean to say on this point is that as there is no in the the power which the government may exercise over the or property of h in a territory thus acquired tlie ck must necessarily look to the provisions and principles of the constitution and its distribution of powers or the rules and by which its decision must be governed taking rule to guide us it maybe safely assumed that of he united states who to a territory belonging to the people of the united states cannot be ruled as mere dependent upon the will of the general government and to be governed by any laws it may think proper to impose the territory being a part of the united the government and the citizen both enter it under the authority of the constitution with their respective rights defined and marked out and the government can exercise bo power over his person or property beyond what that nor deny any right which it has reserved hence inasmuch as the constitution has conferred on the government no right to interfere with the domestic relations or internal y of the people of tlie it necessarily follows under the authority of the court that can exercise no such power over the people of the for this reason alone tiie supreme court were and \",\n          \"not altogether for years and years the colony of has been employed in the construction of a railway with a very narrow which is now open as far as or to within a hundred miles of the border is very poor and in common with the rest of south africa and indeed of the world has lately been passing through a period of great commercial depression the home government has refused to help it to its if it had done so how many hundreds of thousand pounds have been saved to the british during the and wars and has equally refused to allow it to borrow sufficient money to get them constructed with the result that a large amount of the interior trade has already been into other and now a fresh and very real danger not only to bat to i the all imperial in africa has into that is in this country for in africa it has been foreseen for many years above is situated which reaches to the southern shore of one of the finest in the world bay this great in which half a dozen could ride at anchor the only really good haven on the of south africa is fifty five miles in width and twenty in depth that is from east to west it is separated from the of which it is the natural port by about ninety miles of wild and inhabited country the of this splendid port was for many years in dispute between this country and the \\u00e2 whose of it is connected by a strip of coast and who have a fort upon it this dispute was finally referred by lord in to the decision of and on this occasion as on every other in which this country has been weak enough to go to that decision was given against us into the merits of the case it is not necessary to enter further than to say as has already been recently pointed ont by a very able and well informed of the morning post that it is by no means clear by what right the matter was referred to at all the are in possession of the southern shore of the bay including i believe the and island and they are the an independent people the also on it and they are independent what had we to refer their rights to the of the evidence of the exercise of any over these countries is so shadowy that it may be said never to have existed certainly it does not exist now this is a point but it is nothing more we must take things as we find them and we find that the have been formally declared and admitted by us to be the owners of bay now so long as we held the it did not so much matter who had the of the bay since a railway constructed from there could only run to british territory but we gave up the which is now a hostile state and the which has been so long foreseen in south africa and so blindly overlooked at home has come to pass \\u00e2 the railway is in course of rapid completion what does this mean to us at the best it means that we lose the greater part of the trade of south eastern africa at the worst that we lose it all in other words it means putting aside the question of our imperial needs and in africa a great many millions a year in hard cash out of the national pocket let us suppose that the worst happens and that the get a footing in the or bay obviously they will stop our trade in favour of their own or let ui the that the takes advantage of one of our of imperial such as us during the of lord and the provision in the which them to put a heavier tax upon our goods than upon those of any other nation in either event our case would be a bad one for our road from the eastern coast to the vast interior is blocked but it is of little use crying over milk or evils which it is our duty to try to and which in all probability still could be averted by a sound and consistent policy to begin with both and can be to the empire it is true that the independence of the first of these countries is by article xii of the of london of here is the exact \\u00e2 the independence of the within the boundary line of as indicated in the first article of this will be fully recognised but england has for years exercised a kind of right over \\u00e2 a right as i have already shown acknowledged and frequently appealed to by the themselves and for the rest what is the obvious meaning of this provision it means that the independence of is against its object was to protect the from at the hands of the further the have again and again broken this article of the the an in their repeated attempts to get a in it has now become to our interests that the should come under our rule as indeed they are most anxious to do and a way should be found by which this end can be accomplished then as to or as it is sometimes called only a month or two ago an from the queen of that country waited on the office praying for british protection it is not known what answer they received let us trust that it was a favourable one the protection that should be accorded to the both in their interests and our own is to the british empire upon such terms as might be satisfactory to them the management of their country might be left to them subject to the advice of a and the of the ordinary laws \",\n          \"kind offices she could not equal them in their warmth her spirits sank under the glow of theirs and she felt herself becoming too nearly nothing to both to have any comfort in having been sought by either they must now together proposed urged entreated it till the lady not very unwilling at first could refuse no longer \\u00e2 and was wanted only to prompt and observe them she was invested indeed with the office of judge and critic and earnestly desired to exercise it and tell them all their faults but from doing so every feeling within her shrank she could not would not dared not attempt it had she been otherwise qualified for criticism her conscience must have restrained her from venturing at she believed herself to feel too much of it in the for honesty or safety in particulars to prompt them must be enough for her and it was sometimes more than enough for she could not always pay attention to the book in watching them she forgot herself and agitated by the increasing spirit of s manner had once closed the page and turned away exactly as he wanted help it was to very reasonable weariness and she was thanked and pitied but she deserved their pity more than park she hoped they would at last the scene was over and forced herself to add her praise to the compliments each was giving the other and when again alone and able to recall the whole she was inclined to believe their performance would indeed have such nature and feeling in it as must their credit and make it a very suffering exhibition to herself whatever might be its effect however she must stand the of it again that very day the first regular of the three first acts was certainly to take place in the evening mrs grant and the were engaged to return for that purpose as soon as they could after dinner and every one concerned was looking forward with eagerness there seemed a general of cheerfulness on the occasion tom was enjoying such an advance towards the end was in spirits from the morning s and little seemed everywhere smoothed away all were alert and impatient the ladies moved soon the gentlemen soon followed them and with the exception of lady mrs and everybody was in the theatre at an early hour and having lighted it up as well as its unfinished state admitted were waiting only the arrival of mrs grant and the to begin they did not wait long for the but there was no mrs grant she could not come dr grant an for which he had little credit with his fair sister in law could not spare his wife dr grant is ill said she with mock be has been ill r he did not eat any of the to day he fancied it sent ai ray plate and has been suffering ever here was disappointment mrs grant s non attendance was sad indeed her pleasant manners and cheerful made her always valuable amongst them but now she was absolutely they could not act they could not with any satisfaction without her the of the whole evening was destroyed what was to be done tom as was in despair after a pause of perplexity some eyes began to be turned towards and a voice or two to say if miss price would be so good as to read the part she was immediately surrounded by \\u00e2 everybody asked it even said do if it is not very disagreeable to you but still hung back she could not endure the idea of it why was not miss to be applied to as well or why had not she rather gone to her own room as she had felt to be safest instead of attending the at all she had known it would and distress her \\u00e2 she had known it her duty to keep away she was properly punished you have only to read the part said henry with renewed entreaty and i do believe she can say every word of it added maria for she could put mrs grant right the other day in twenty places i am sure you know the part vol i \\u00e2 could not say she did not and as they all \\u00e2 as repeated his wish and with a look of even fond dependence on her \\u00e2 she must yield she would do her everybody was satisfied and she was left to the of a most heart while the others prepared to begin they did begin and being too much engaged in their own noise to be struck by an unusual noise in the other part of the house had proceeded some way when the door of the room was thrown open and appearing at it with a face all aghast exclaimed my father is come i he is in the hall at this moment xix how the consternation of the party to be described to the greater number it was a moment of absolute horror sir thomas in the house all felt the conviction not a hope of or mistake was anywhere s looks were an evidence of the fact that made it and after the first starts and exclamations not a word was spoken for a minute each with an altered countenance was looking at some other and almost each was feeling it a stroke the most unwelcome most ill timed most appalling mr might consider it only as a interruption for the evening and mr might imagine it a blessing but every other heart was sinking under some degree of self condemnation or alarm \\u00e2 every other heart was suggesting what will become of us what is to be done now it was a terrible pause and terrible to every ear were the sounds of opening doors and passing footsteps was the first to move and speak again jealousy and \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 1,\n        \"max\": 50,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          32,\n          19,\n          41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# data_path = r'Data\\Gungor_2018_VictorianAuthorAttribution_data-train.csv'\n",
        "# df = pd.read_csv(data_path, encoding='latin-1')\n",
        "\n",
        "## URL from github repo, load as dataframe\n",
        "url = 'https://raw.githubusercontent.com/ccsarmientot/text_author_classifier/master/datasets/sample_victorian.parquet'\n",
        "# url = 'datasets/sample_victorian.parquet'\n",
        "df = pd.read_parquet(url)\n",
        "\n",
        "print(f'Shape of dataframe: {df.shape}')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgNrOlCA2LL7",
        "outputId": "46a262fb-863a-4c8f-b907-0a4b87d711d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cantidad promedio de caracteres por texto: 4,945.23'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "avg_chr = np.mean(df['text'].apply(len))\n",
        "f'Cantidad promedio de caracteres por texto: {avg_chr:,.2f}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4wnIr012LL8",
        "outputId": "f38843e8-0d85-4368-c1f4-5b5c26179d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cantidad promedio de palabras por texto: 1,001.00'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "avg_chr = np.mean(df['text'].apply(lambda x: len(x.split(' '))))\n",
        "f'Cantidad promedio de palabras por texto: {avg_chr:,.2f}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1x0X4z52LL9",
        "outputId": "9032f5db-7e1a-4aaf-e565-54f33a2b8f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "author\n",
              "8     1336\n",
              "26     869\n",
              "14     501\n",
              "21     448\n",
              "37     441\n",
              "39     434\n",
              "45     424\n",
              "33     347\n",
              "48     342\n",
              "19     330\n",
              "15     244\n",
              "4      240\n",
              "43     228\n",
              "9      213\n",
              "38     209\n",
              "25     207\n",
              "18     200\n",
              "30     182\n",
              "42     178\n",
              "1      174\n",
              "50     162\n",
              "41     159\n",
              "32     139\n",
              "10     138\n",
              "28     132\n",
              "17     128\n",
              "36     120\n",
              "35     118\n",
              "12     112\n",
              "44     110\n",
              "20     110\n",
              "46     107\n",
              "13      92\n",
              "29      89\n",
              "34      85\n",
              "22      85\n",
              "24      82\n",
              "23      80\n",
              "40      78\n",
              "11      66\n",
              "27      63\n",
              "6       63\n",
              "2       62\n",
              "3       41\n",
              "16      32\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>author</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "## Se identifica un desbalance de clases:\n",
        "df['author'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbpjNNgm2LL-"
      },
      "outputs": [],
      "source": [
        "# ## Getting sample fo\n",
        "# df_sample = df.sample(10_000)\n",
        "# n_authors = df_sample['author'].nunique()\n",
        "# print(f'Authors in df_sample: {n_authors}')\n",
        "# df_sample.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WSb4OtL2LL-"
      },
      "source": [
        "## 2. Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18BFAhKj2LL_"
      },
      "outputs": [],
      "source": [
        "# Importamos librerias\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "results = []\n",
        "X = df['text']\n",
        "y = df['author']\n",
        "\n",
        "# Dividimos los datos en entrenamiento y testeo\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efZ0ShaU2LL_"
      },
      "outputs": [],
      "source": [
        "## Se aplica el preprocesameinto\n",
        "\n",
        "# 1. Feature Extraction\n",
        "tfidf = TfidfVectorizer(max_features=1000, preprocessor=preprocess_text)\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_test = tfidf.transform(X_test)\n",
        "\n",
        "# 2. Oversampling\n",
        "oversample = RandomOverSampler()\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLTHQB_02LMA"
      },
      "source": [
        "### 2.0 Define function to iterate over"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcuImEdu2LMA"
      },
      "outputs": [],
      "source": [
        "def train_cv_models(model_name:str, classifier,\n",
        "                    param_grid:dict[list],\n",
        "                    X_train, y_train) -> dict:\n",
        "\n",
        "    # Creacion del pipeline del modelo inicial\n",
        "    model = Pipeline(steps=[\n",
        "        ## Se aplica el modelo\n",
        "        (model_name, classifier)\n",
        "    ])\n",
        "\n",
        "    ######################## PRIMERA BÚSQUEDA DE PARÁMETROS ####################\n",
        "    print(' Primera búsqueda de parámetros '.center(80, '#'))\n",
        "\n",
        "    # Creamos el objeto GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, verbose=2)\n",
        "\n",
        "    # Ajustamos el modelo a los datos de entrenamiento\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Obtenemos los mejores parámetros\n",
        "    best_params = grid_search.best_params_\n",
        "    print(f'Resultados primera búsqueda: {best_params}', '\\n')\n",
        "\n",
        "    ######################## SEGUNDA BÚSQUEDA DE PARÁMETROS ####################\n",
        "    print(' Segunda búsqueda de parámetros '.center(80, '#'), '\\n')\n",
        "\n",
        "\n",
        "    # A los parámetros que deben ser enteros se resta y suma 1\n",
        "    int_list = ['min_samples_split', 'max_depth', 'n_neighbors', 'min_samples_leaf']\n",
        "    int_grid = {k:[v-1, v, v+1] for k,v in best_params.items() if any([i in k for i in int_list])}\n",
        "    ## Clean zero values\n",
        "    int_grid = {k:[c for c in v if c != 0] for k,v in int_grid.items()}\n",
        "\n",
        "    # A los parámetros numéricos encontrados se resta y suma el 10 %\n",
        "    int_params_grid = {k:[v-(v/10), v, v+(v/10)] for k,v in best_params.items() if isinstance(v, (float, int))}\n",
        "\n",
        "    # A los parámetros en formato string encontrados se deja el mejor\n",
        "    str_params_grid = {k:[v] for k,v in best_params.items() if not isinstance(v, list)}\n",
        "\n",
        "    best_params_grid = {**str_params_grid, **int_params_grid, **int_grid}\n",
        "    # best_params_grid['tfidf__max_features'] = [1000]\n",
        "\n",
        "    print('DEBUG: params after transform: ', best_params_grid)\n",
        "\n",
        "    # Creamos el objeto GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=best_params_grid, cv=2, verbose=2)\n",
        "\n",
        "    # Ajustamos el modelo a los datos de entrenamiento\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Obtenemos los mejores parámetros\n",
        "    best_params = grid_search.best_params_\n",
        "    print(f'Resultados segunda búsqueda: {best_params}', '\\n')\n",
        "\n",
        "    return best_params\n",
        "\n",
        "\n",
        "def train_final_model(model_name, classifier, X_train, y_train) -> list:\n",
        "\n",
        "    print(' Creando modelo final con los mejores parámetros '.center(80, '#'))\n",
        "\n",
        "    # Creacion del pipeline modelo final\n",
        "    final_model = Pipeline(steps=[\n",
        "        ## Se aplica el modelo\n",
        "        (model_name, classifier)\n",
        "    ])\n",
        "\n",
        "    # Ajuste del modelo\n",
        "    final_model.fit(X_train, y_train)\n",
        "\n",
        "    # Medimos el accuracy del modelo\n",
        "    accuracy = final_model.score(X_test, y_test)\n",
        "    print(f'Accuracy de {model_name}: {accuracy:,.2%}')\n",
        "\n",
        "    # Se predicen las clases para test\n",
        "    y_pred = final_model.predict(X_test)\n",
        "\n",
        "    p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "    return [model_name, accuracy, p, r, f1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH03YO4y2LMC"
      },
      "source": [
        "### 2.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyMmQSlB2LMC",
        "outputId": "3404a8c4-41ea-425c-a68e-99883abeed9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################## Primera búsqueda de parámetros ########################\n",
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "[CV] END ..........................LogisticRegression__C=0.1; total time=   8.6s\n",
            "[CV] END ..........................LogisticRegression__C=0.1; total time=   7.9s\n",
            "[CV] END ............................LogisticRegression__C=1; total time=  18.4s\n",
            "[CV] END ............................LogisticRegression__C=1; total time=  22.0s\n",
            "[CV] END ...........................LogisticRegression__C=10; total time=  29.9s\n",
            "[CV] END ...........................LogisticRegression__C=10; total time=  27.2s\n",
            "Resultados primera búsqueda: {'LogisticRegression__C': 10} \n",
            "\n",
            "######################## Segunda búsqueda de parámetros ######################## \n",
            "\n",
            "DEBUG: params after transform:  {'LogisticRegression__C': [9.0, 10, 11.0]}\n",
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "[CV] END ..........................LogisticRegression__C=9.0; total time=  30.0s\n",
            "[CV] END ...........................LogisticRegression__C=10; total time=  28.7s\n",
            "[CV] END ...........................LogisticRegression__C=10; total time=  26.8s\n",
            "[CV] END .........................LogisticRegression__C=11.0; total time=  25.8s\n",
            "[CV] END .........................LogisticRegression__C=11.0; total time=  27.7s\n",
            "Resultados segunda búsqueda: {'LogisticRegression__C': 11.0} \n",
            "\n",
            "############### Creando modelo final con los mejores parámetros ################\n",
            "Accuracy de LogisticRegression: 88.55%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = LogisticRegression()\n",
        "model_name = 'LogisticRegression'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__C': [0.1, 1, 10],\n",
        "}\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "\n",
        "best_classifier = LogisticRegression(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2UJ-c_K2LMD"
      },
      "source": [
        "### 2.2 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WdV8DOu2LMD",
        "outputId": "1d739d1b-b851-411f-8742-6ef2914998bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################## Primera búsqueda de parámetros ########################\n",
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.3s\n",
            "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.3s\n",
            "[CV] END ................................NaiveBayes__alpha=1; total time=   0.3s\n",
            "[CV] END ................................NaiveBayes__alpha=1; total time=   0.3s\n",
            "[CV] END ...............................NaiveBayes__alpha=10; total time=   0.3s\n",
            "[CV] END ...............................NaiveBayes__alpha=10; total time=   0.3s\n",
            "Resultados primera búsqueda: {'NaiveBayes__alpha': 0.1} \n",
            "\n",
            "######################## Segunda búsqueda de parámetros ######################## \n",
            "\n",
            "DEBUG: params after transform:  {'NaiveBayes__alpha': [0.09000000000000001, 0.1, 0.11]}\n",
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "[CV] END ..............NaiveBayes__alpha=0.09000000000000001; total time=   0.3s\n",
            "[CV] END ..............NaiveBayes__alpha=0.09000000000000001; total time=   0.3s\n",
            "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.3s\n",
            "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.3s\n",
            "[CV] END .............................NaiveBayes__alpha=0.11; total time=   0.3s\n",
            "[CV] END .............................NaiveBayes__alpha=0.11; total time=   0.3s\n",
            "Resultados segunda búsqueda: {'NaiveBayes__alpha': 0.09000000000000001} \n",
            "\n",
            "############### Creando modelo final con los mejores parámetros ################\n",
            "Accuracy de NaiveBayes: 78.30%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = MultinomialNB()\n",
        "model_name = 'NaiveBayes'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__alpha': [0.1, 1, 10],\n",
        "}\n",
        "\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "\n",
        "best_classifier = MultinomialNB(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCPCCGZg2LME"
      },
      "source": [
        "### 2.3 KNeighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIstGsSm2LME",
        "outputId": "f9a08641-fd3b-46e0-cde0-466524f5a379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######################## Primera búsqueda de parámetros ########################\n",
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 2.0min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=5; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=5; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=3; total time= 7.7min\n",
            "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=3; total time= 7.6min\n",
            "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=5; total time= 7.6min\n",
            "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=5; total time= 7.6min\n",
            "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=3; total time= 2.0min\n",
            "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=3; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=5; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=5; total time= 1.9min\n",
            "Resultados primera búsqueda: {'KNeighbors__metric': 'euclidean', 'KNeighbors__n_neighbors': 3} \n",
            "\n",
            "######################## Segunda búsqueda de parámetros ######################## \n",
            "\n",
            "DEBUG: params after transform:  {'KNeighbors__metric': ['euclidean'], 'KNeighbors__n_neighbors': [2, 3, 4]}\n",
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=2; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=2; total time= 2.0min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=4; total time= 1.9min\n",
            "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=4; total time= 1.9min\n",
            "Resultados segunda búsqueda: {'KNeighbors__metric': 'euclidean', 'KNeighbors__n_neighbors': 2} \n",
            "\n",
            "############### Creando modelo final con los mejores parámetros ################\n",
            "Accuracy de KNeighbors: 67.95%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = KNeighborsClassifier()\n",
        "model_name = 'KNeighbors'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__n_neighbors': [3, 5],\n",
        "    f'{model_name}__metric': ['euclidean', 'manhattan', 'cosine']\n",
        "}\n",
        "\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "best_classifier = KNeighborsClassifier(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zJnuGaK2LMF"
      },
      "source": [
        "### 2.4 Arboles de decisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFqxhzxJ2LMF",
        "outputId": "0dc64206-82a7-4a13-8e98-fefcfb44ca30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######################## Primera búsqueda de parámetros ########################\n",
            "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=   3.0s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=   4.1s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=   3.3s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=   3.2s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=   3.0s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=   3.8s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=   3.3s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=   3.2s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=   6.9s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=   7.0s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=   7.0s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=   6.9s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  10.4s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=   6.9s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=   7.2s\n",
            "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=   6.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=   9.8s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  10.7s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=   8.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  10.7s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  10.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  10.5s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=   8.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  10.4s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  24.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  26.1s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  23.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  25.7s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  24.4s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  25.8s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  24.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  26.0s\n",
            "Resultados primera búsqueda: {'DecisionTree__criterion': 'entropy', 'DecisionTree__max_depth': 10, 'DecisionTree__min_samples_leaf': 2, 'DecisionTree__min_samples_split': 5} \n",
            "\n",
            "######################## Segunda búsqueda de parámetros ######################## \n",
            "\n",
            "DEBUG: params after transform:  {'DecisionTree__criterion': ['entropy'], 'DecisionTree__max_depth': [9, 10, 11], 'DecisionTree__min_samples_leaf': [1, 2, 3], 'DecisionTree__min_samples_split': [4, 5, 6]}\n",
            "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=4; total time=  19.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=4; total time=  22.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=5; total time=  19.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=5; total time=  22.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=6; total time=  19.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=6; total time=  22.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=4; total time=  19.5s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=4; total time=  21.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  20.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  21.1s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time=  20.5s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time=  20.9s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=4; total time=  20.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=4; total time=  20.8s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  20.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  20.7s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time=  20.5s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=9, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time=  21.1s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=4; total time=  24.5s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=4; total time=  26.5s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=5; total time=  24.5s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=5; total time=  26.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=6; total time=  24.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=6; total time=  26.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=4; total time=  23.4s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=4; total time=  28.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  23.9s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  26.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time=  24.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time=  26.1s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=4; total time=  24.1s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=4; total time=  26.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  23.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  26.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time=  24.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time=  26.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=4; total time=  27.9s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=4; total time=  30.3s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=5; total time=  28.7s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=5; total time=  30.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=6; total time=  27.8s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=1, DecisionTree__min_samples_split=6; total time=  30.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=4; total time=  27.7s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=4; total time=  30.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  28.0s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  31.1s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time=  27.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time=  29.9s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=4; total time=  27.6s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=4; total time=  29.8s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  27.7s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  31.2s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time=  27.4s\n",
            "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time=  29.5s\n",
            "Resultados segunda búsqueda: {'DecisionTree__criterion': 'entropy', 'DecisionTree__max_depth': 11, 'DecisionTree__min_samples_leaf': 1, 'DecisionTree__min_samples_split': 4} \n",
            "\n",
            "############### Creando modelo final con los mejores parámetros ################\n",
            "Accuracy de DecisionTree: 17.35%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = DecisionTreeClassifier()\n",
        "model_name = 'DecisionTree'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__criterion': ['gini', 'entropy'],\n",
        "    f'{model_name}__max_depth': [5, 10],\n",
        "    f'{model_name}__min_samples_split': [5, 10],\n",
        "    f'{model_name}__min_samples_leaf': [2, 3]\n",
        "}\n",
        "\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "\n",
        "best_classifier = DecisionTreeClassifier(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h6D8Dzw2LMG"
      },
      "source": [
        "### 2.5 Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ2bV7Ov2LMH",
        "outputId": "a3efa483-4b96-4629-f6ba-2328a2370fe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################## Primera búsqueda de parámetros ########################\n",
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "[CV] END .......SVC__C=1, SVC__gamma=0.1, SVC__kernel=linear; total time=13.9min\n",
            "[CV] END .......SVC__C=1, SVC__gamma=0.1, SVC__kernel=linear; total time=14.7min\n",
            "[CV] END ..........SVC__C=1, SVC__gamma=0.1, SVC__kernel=rbf; total time=32.6min\n",
            "[CV] END ..........SVC__C=1, SVC__gamma=0.1, SVC__kernel=rbf; total time=33.7min\n",
            "[CV] END .........SVC__C=1, SVC__gamma=1, SVC__kernel=linear; total time=13.7min\n",
            "[CV] END .........SVC__C=1, SVC__gamma=1, SVC__kernel=linear; total time=14.8min\n",
            "[CV] END ............SVC__C=1, SVC__gamma=1, SVC__kernel=rbf; total time=16.9min\n",
            "[CV] END ............SVC__C=1, SVC__gamma=1, SVC__kernel=rbf; total time=18.1min\n",
            "[CV] END ......SVC__C=10, SVC__gamma=0.1, SVC__kernel=linear; total time=10.2min\n",
            "[CV] END ......SVC__C=10, SVC__gamma=0.1, SVC__kernel=linear; total time=11.1min\n",
            "[CV] END .........SVC__C=10, SVC__gamma=0.1, SVC__kernel=rbf; total time=12.2min\n",
            "[CV] END .........SVC__C=10, SVC__gamma=0.1, SVC__kernel=rbf; total time=13.3min\n",
            "[CV] END ........SVC__C=10, SVC__gamma=1, SVC__kernel=linear; total time=10.3min\n",
            "[CV] END ........SVC__C=10, SVC__gamma=1, SVC__kernel=linear; total time=11.1min\n",
            "[CV] END ...........SVC__C=10, SVC__gamma=1, SVC__kernel=rbf; total time=13.9min\n",
            "[CV] END ...........SVC__C=10, SVC__gamma=1, SVC__kernel=rbf; total time=15.1min\n",
            "Resultados primera búsqueda: {'SVC__C': 10, 'SVC__gamma': 1, 'SVC__kernel': 'rbf'} \n",
            "\n",
            "######################## Segunda búsqueda de parámetros ######################## \n",
            "\n",
            "DEBUG: params after transform:  {'SVC__C': [9.0, 10, 11.0], 'SVC__gamma': [0.9, 1, 1.1], 'SVC__kernel': ['rbf']}\n",
            "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
            "[CV] END ........SVC__C=9.0, SVC__gamma=0.9, SVC__kernel=rbf; total time=13.6min\n",
            "[CV] END ........SVC__C=9.0, SVC__gamma=0.9, SVC__kernel=rbf; total time=14.7min\n",
            "[CV] END ..........SVC__C=9.0, SVC__gamma=1, SVC__kernel=rbf; total time=13.8min\n",
            "[CV] END ..........SVC__C=9.0, SVC__gamma=1, SVC__kernel=rbf; total time=15.0min\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = SVC()\n",
        "model_name = 'SVC'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__C': [1, 10],\n",
        "    f'{model_name}__kernel': ['linear', 'rbf'],\n",
        "    f'{model_name}__gamma': [0.1, 1]\n",
        "}\n",
        "\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "\n",
        "best_classifier = SVC(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-xFfcG82LMI"
      },
      "source": [
        "### 2.6 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74hmGKsU2LMI",
        "outputId": "9c2e4444-9770-4f38-de32-f1beff52fbb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################## Primera búsqueda de parámetros ########################\n",
            "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  10.0s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=   9.8s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  18.5s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  19.2s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  10.0s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  10.6s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  18.9s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  19.6s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=   9.4s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  10.4s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  18.4s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  20.0s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=   8.6s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  10.1s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  18.2s\n",
            "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  19.7s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  22.6s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  23.5s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  45.4s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  47.1s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  23.1s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  23.7s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  45.8s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  47.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  21.8s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  23.3s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  44.9s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  46.3s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  22.1s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  23.7s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  44.4s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  46.4s\n",
            "Resultados primera búsqueda: {'RandomForest__max_depth': 10, 'RandomForest__min_samples_leaf': 2, 'RandomForest__min_samples_split': 2, 'RandomForest__n_estimators': 200} \n",
            "\n",
            "######################## Segunda búsqueda de parámetros ######################## \n",
            "\n",
            "DEBUG: params after transform:  {'RandomForest__max_depth': [9, 10, 11], 'RandomForest__min_samples_leaf': [1, 2, 3], 'RandomForest__min_samples_split': [1, 2, 3], 'RandomForest__n_estimators': [180.0, 200, 220.0]}\n",
            "Fitting 2 folds for each of 81 candidates, totalling 162 fits\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  39.5s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  40.3s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  41.6s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  41.7s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  38.5s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  40.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  39.2s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  38.6s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  39.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  39.9s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  39.5s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  40.5s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  46.2s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  47.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  46.1s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  46.4s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  48.3s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  47.1s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  46.1s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  47.3s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  44.7s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  45.8s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  45.9s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  45.7s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  53.9s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  55.3s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  53.4s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  54.3s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  52.5s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  54.2s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  54.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  54.4s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  53.1s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  54.7s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  53.5s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  53.2s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
            "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "126 fits failed out of a total of 162.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "54 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n",
            "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "36 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n",
            "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of RandomForestClassifier must be an int in the range [1, inf). Got 180.0 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "36 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n",
            "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of RandomForestClassifier must be an int in the range [1, inf). Got 220.0 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.90786585        nan\n",
            "        nan 0.90600532        nan        nan        nan        nan\n",
            "        nan 0.89548337        nan        nan 0.89647565        nan\n",
            "        nan        nan        nan        nan 0.88246007        nan\n",
            "        nan 0.88740073        nan        nan        nan        nan\n",
            "        nan 0.93263068        nan        nan 0.93312679        nan\n",
            "        nan        nan        nan        nan 0.92372106        nan\n",
            "        nan 0.92390713        nan        nan        nan        nan\n",
            "        nan 0.9135919         nan        nan 0.91394323        nan\n",
            "        nan        nan        nan        nan 0.95158675        nan\n",
            "        nan 0.94817589        nan        nan        nan        nan\n",
            "        nan 0.94098212        nan        nan 0.94232578        nan\n",
            "        nan        nan        nan        nan 0.93403634        nan\n",
            "        nan 0.9300673         nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados segunda búsqueda: {'RandomForest__max_depth': 11, 'RandomForest__min_samples_leaf': 1, 'RandomForest__min_samples_split': 2, 'RandomForest__n_estimators': 200} \n",
            "\n",
            "############### Creando modelo final con los mejores parámetros ################\n",
            "Accuracy de RandomForest: 57.40%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = RandomForestClassifier()\n",
        "model_name = 'RandomForest'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__n_estimators': [100, 200],\n",
        "    f'{model_name}__max_depth': [5, 10],\n",
        "    f'{model_name}__min_samples_split': [2, 5],\n",
        "    f'{model_name}__min_samples_leaf': [2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "\n",
        "best_classifier = RandomForestClassifier(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXHkiYVd2LMJ"
      },
      "source": [
        "### 2.7 MLP Classifier (Multi-Layer Perceptron)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAYvPCbc2LMK"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = MLPClassifier()\n",
        "model_name = 'MLP'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__hidden_layer_sizes': [(100, 50), (50, 50)],\n",
        "    f'{model_name}__activation': ['relu', 'tanh'],\n",
        "    f'{model_name}__solver': ['adam', 'sgd'],\n",
        "    f'{model_name}__alpha': [0.001, 0.01],\n",
        "    f'{model_name}__learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "\n",
        "best_classifier = MLPClassifier(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy-7lmOH2LML"
      },
      "source": [
        "### 2.8 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX9VGUkq2LML",
        "outputId": "76fc76ab-7388-4586-d1f9-9c53fa9f96ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################## Primera búsqueda de parámetros ########################\n",
            "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.1s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
            "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 32 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n32 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44], got [ 1  2  3  4  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n 27 28 29 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 50]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-866907a39f73>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cv_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel_best_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'tfidf'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-3ceb9d510839>\u001b[0m in \u001b[0;36mtrain_cv_models\u001b[0;34m(model_name, classifier, param_grid, X_train, y_train)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Ajustamos el modelo a los datos de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Obtenemos los mejores parámetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     )\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             )\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 32 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n32 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44], got [ 1  2  3  4  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n 27 28 29 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 50]\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Definimos el modelo a usar\n",
        "classifier = xgb.XGBClassifier()\n",
        "model_name = 'XGB'\n",
        "\n",
        "# Definimos los parámetros a explorar\n",
        "param_grid = {\n",
        "\n",
        "    f'{model_name}__max_depth': [3, 5],\n",
        "    f'{model_name}__learning_rate': [0.1, 0.3],\n",
        "    f'{model_name}__subsample': [0.8, 1.0],\n",
        "    f'{model_name}__colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
        "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
        "\n",
        "best_classifier = xgb.XGBClassifier(**model_best_params)\n",
        "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
        "results.append(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NwP8TxN2LMM"
      },
      "source": [
        "## 3. Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMwu-tEU2LMN"
      },
      "outputs": [],
      "source": [
        "res_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
        "res_df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env_nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}