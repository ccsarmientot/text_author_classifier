{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Libraries and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove accents\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Limpiamos el texto\n",
    "preprocess_text('What can I say, I love this place')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = r'Data\\Gungor_2018_VictorianAuthorAttribution_data-train.csv'\n",
    "# df = pd.read_csv(data_path, encoding='latin-1')\n",
    "\n",
    "## URL from github repo, load as dataframe\n",
    "url = 'https://raw.githubusercontent.com/ccsarmientot/text_author_classifier/master/datasets/sample_victorian.parquet'\n",
    "url = 'datasets/sample_victorian.parquet'\n",
    "df = pd.read_parquet(url)\n",
    "\n",
    "## To comment\n",
    "df = df.sample(500)\n",
    "\n",
    "print(f'Shape of dataframe: {df.shape}')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_chr = np.mean(df['text'].apply(len))\n",
    "f'Cantidad promedio de caracteres por texto: {avg_chr:,.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_chr = np.mean(df['text'].apply(lambda x: len(x.split(' '))))\n",
    "f'Cantidad promedio de palabras por texto: {avg_chr:,.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se identifica un desbalance de clases:\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Getting sample fo \n",
    "# df_sample = df.sample(10_000)\n",
    "# n_authors = df_sample['author'].nunique()\n",
    "# print(f'Authors in df_sample: {n_authors}')\n",
    "# df_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "results = []\n",
    "X = df['text']\n",
    "y = df['author']\n",
    "\n",
    "# Dividimos los datos en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"logit\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'logit__C': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'logit__C': [9, 10, 11],\n",
    "# }\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"logit\", LogisticRegression(C=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'Logistic_regresion'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"naive\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'naive__alpha': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'naive__alpha': [0.1, 1, 10],\n",
    "# }\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"naive\", MultinomialNB(alpha=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'NaiveBayes'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"kneig\", KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'kneig__n_neighbors': [3, 5],\n",
    "    'kneig__metric': ['euclidean', 'manhattan', 'cosine']\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'kneig__n_neighbors': [3, 5],\n",
    "#     'kneig__metric': ['euclidean', 'manhattan', 'cosine']\n",
    "# }\n",
    "\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"kneig\", KNeighborsClassifier(n_neighbors=3, metric='euclidean'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'K-neighbors'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Arboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"tree\", DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'tree__criterion': ['gini', 'entropy'],\n",
    "    'tree__max_depth': [5, 10],\n",
    "    'tree__min_samples_split': [5, 10],\n",
    "    'tree__min_samples_leaf': [1, 3]\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'tree__criterion': ['gini', 'entropy'],\n",
    "#     'tree__max_depth': [5, 10],\n",
    "#     'tree__min_samples_split': [5, 10],\n",
    "#     'tree__min_samples_leaf': [1, 3]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"tree\", DecisionTreeClassifier(max_depth=5, min_samples_split=5, \n",
    "                                    min_samples_leaf=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'Decision Trees'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"SVC\", SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'SVC__C': [0.1, 1, 10, 100],\n",
    "    'SVC__kernel': ['linear', 'rbf'],\n",
    "    'SVC__gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'SVC__C': [0.1, 1, 10, 100],\n",
    "#     'SVC__kernel': ['linear', 'rbf'],\n",
    "#     'SVC__gamma': [0.1, 1, 10]\n",
    "# }\n",
    "\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"SVC\", SVC(C=0.1, kernel='linear', gamma=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'SVC'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"rforest\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'rforest__n_estimators': [100, 200],\n",
    "    'rforest__max_depth': [5, 10],\n",
    "    'rforest__min_samples_split': [2, 5],\n",
    "    'rforest__min_samples_leaf': [2, 4]\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'rforest__n_estimators': [100, 200],\n",
    "#     'rforest__max_depth': [5, 10],\n",
    "#     'rforest__min_samples_split': [2, 5],\n",
    "#     'rforest__min_samples_leaf': [2, 4]\n",
    "# }\n",
    "\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"rforest\", RandomForestClassifier(n_estimators=100, max_depth=5, \n",
    "                                       min_samples_split=2, min_samples_leaf=2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'Random Forest'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"XGB\", xgb())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'XGB__max_depth': [3, 5],\n",
    "    'XGB__learning_rate': [0.1, 0.3],\n",
    "    'XGB__subsample': [0.8, 1.0],\n",
    "    'XGB__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'XGB__max_depth': [3, 5],\n",
    "#     'XGB__learning_rate': [0.1, 0.3],\n",
    "#     'XGB__subsample': [0.8, 1.0],\n",
    "#     'XGB__colsample_bytree': [0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"XGB\", xgb(max_depth=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0-8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'XGBoost'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 MLP Classifier (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Creacion del pipeline del modelo inicial\n",
    "model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"MLP\", MLPClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.1 Primera iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000],\n",
    "    'MLP__hidden_layer_sizes': [(100, 50), (50, 50)],\n",
    "    'MLP__activation': ['relu', 'tanh'],\n",
    "    'MLP__solver': ['adam', 'sgd'],\n",
    "    'MLP__alpha': [0.001, 0.01],\n",
    "    'MLP__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.2 Segunda iteración grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos los parámetros a explorar\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [1000],\n",
    "#     'MLP__hidden_layer_sizes': [(100, 50), (50, 50)],\n",
    "#     'MLP__activation': ['relu', 'tanh'],\n",
    "#     'MLP__solver': ['adam', 'sgd'],\n",
    "#     'MLP__alpha': [0.001, 0.01],\n",
    "#     'MLP__learning_rate': ['constant', 'adaptive']\n",
    "# }\n",
    "\n",
    "\n",
    "# # Creamos el objeto GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model,\n",
    "#                           param_grid=param_grid,\n",
    "#                           cv=5,\n",
    "#                           verbose=2)\n",
    "\n",
    "# # Ajustamos el modelo a los datos de entrenamiento\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Obtenemos los mejores parámetros\n",
    "# best_params = grid_search.best_params_\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.3 Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion del pipeline\n",
    "final_model = Pipeline(steps=[\n",
    "    ## Selección de los features\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=500, preprocessor=preprocess_text)),\n",
    "    ## Se tiene un desbalance de clases, entonces se hace un oversampling\n",
    "    ('oversample', RandomOverSampler()),\n",
    "    ## Se aplica el modelo\n",
    "    (\"MLP\", MLPClassifier(hidden_layer_sizes=(50, 50), activation='relu', \n",
    "                          solver='sgd', alpha=0.01, learning_rate='adaptative'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medimos el accuracy del modelo\n",
    "accuracy = final_model.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se predicen las clases para test\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8.4 Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "model_name = 'MLP'\n",
    "results.append([model_name, accuracy, p, r, f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
