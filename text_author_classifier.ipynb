{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Libraries and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0860770\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\A0860770\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say love place'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove accents\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Limpiamos el texto\n",
    "preprocess_text('What can I say, I love this place')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (53678, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ou have time to listen i will give you the ent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish for solitude he was twenty years of age a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and the skirt blew in perfect freedom about th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of san and the rows of shops opposite impresse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an hour s walk was as tiresome as three in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  ou have time to listen i will give you the ent...       1\n",
       "1  wish for solitude he was twenty years of age a...       1\n",
       "2  and the skirt blew in perfect freedom about th...       1\n",
       "3  of san and the rows of shops opposite impresse...       1\n",
       "4  an hour s walk was as tiresome as three in a s...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'Data\\Gungor_2018_VictorianAuthorAttribution_data-train.csv'\n",
    "df = pd.read_csv(data_path, encoding='latin-1')\n",
    "\n",
    "# ## URL from github repo, load as dataframe\n",
    "# url = 'https://raw.githubusercontent.com/ccsarmientot/text_author_classifier/master/datasets/sample_victorian.parquet'\n",
    "# url = 'datasets/sample_victorian.parquet'\n",
    "# df = pd.read_parquet(url)\n",
    "\n",
    "print(f'Shape of dataframe: {df.shape}')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cantidad promedio de caracteres por texto: 4,942.97'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_chr = np.mean(df['text'].apply(len))\n",
    "f'Cantidad promedio de caracteres por texto: {avg_chr:,.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cantidad promedio de palabras por texto: 1,001.00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_chr = np.mean(df['text'].apply(lambda x: len(x.split(' '))))\n",
    "f'Cantidad promedio de palabras por texto: {avg_chr:,.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "8     6914\n",
       "26    4441\n",
       "14    2696\n",
       "37    2387\n",
       "45    2312\n",
       "21    2307\n",
       "39    2266\n",
       "48    1825\n",
       "33    1742\n",
       "19    1543\n",
       "4     1483\n",
       "15    1460\n",
       "43    1266\n",
       "38    1163\n",
       "25    1159\n",
       "9     1108\n",
       "18    1078\n",
       "42    1022\n",
       "30     972\n",
       "50     914\n",
       "1      912\n",
       "41     911\n",
       "28     823\n",
       "10     755\n",
       "32     703\n",
       "36     693\n",
       "17     660\n",
       "35     659\n",
       "29     645\n",
       "12     627\n",
       "46     605\n",
       "20     587\n",
       "22     495\n",
       "13     485\n",
       "44     468\n",
       "23     455\n",
       "34     453\n",
       "40     430\n",
       "6      407\n",
       "11     383\n",
       "2      382\n",
       "24     380\n",
       "27     306\n",
       "3      213\n",
       "16     183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Se identifica un desbalance de clases:\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Getting sample fo \n",
    "# df_sample = df.sample(10_000)\n",
    "# n_authors = df_sample['author'].nunique()\n",
    "# print(f'Authors in df_sample: {n_authors}')\n",
    "# df_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "results = []\n",
    "X = df['text']\n",
    "y = df['author']\n",
    "\n",
    "# Dividimos los datos en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se aplica el preprocesameinto\n",
    "\n",
    "# 1. Feature Extraction\n",
    "tfidf = TfidfVectorizer(max_features=1000, preprocessor=preprocess_text)\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "\n",
    "# 2. Oversampling\n",
    "oversample = RandomOverSampler()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Define function to iterate over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv_models(model_name:str, classifier, \n",
    "                    param_grid:dict[list], \n",
    "                    X_train, y_train) -> dict:\n",
    "\n",
    "    # Creacion del pipeline del modelo inicial\n",
    "    model = Pipeline(steps=[\n",
    "        ## Se aplica el modelo\n",
    "        (model_name, classifier)\n",
    "    ])\n",
    "\n",
    "    ######################## PRIMERA BÚSQUEDA DE PARÁMETROS ####################\n",
    "    print(' Primera búsqueda de parámetros '.center(80, '#'))\n",
    "\n",
    "    # Creamos el objeto GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=2)\n",
    "\n",
    "    # Ajustamos el modelo a los datos de entrenamiento\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Obtenemos los mejores parámetros\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f'Resultados primera búsqueda: {best_params}', '\\n')\n",
    "\n",
    "    ######################## SEGUNDA BÚSQUEDA DE PARÁMETROS ####################\n",
    "    print(' Segunda búsqueda de parámetros '.center(80, '#'), '\\n')\n",
    "    \n",
    "\n",
    "    # A los parámetros que deben ser enteros se resta y suma 1\n",
    "    int_list = ['min_samples_split', 'max_depth', 'n_neighbors', 'min_samples_leaf', 'n_estimators']\n",
    "    int_grid = {k:[v, v+1] for k,v in best_params.items() if any([i in k for i in int_list])}\n",
    "    ## Clean zero values\n",
    "    int_grid = {k:[c for c in v if c != 0] for k,v in int_grid.items()}\n",
    "\n",
    "    # A los parámetros numéricos encontrados se resta y suma el 10 %\n",
    "    int_params_grid = {k:[v-(v/10), v, v+(v/10)] for k,v in best_params.items() if isinstance(v, (float, int))}\n",
    "    \n",
    "    # A los parámetros en formato string encontrados se deja el mejor\n",
    "    str_params_grid = {k:[v] for k,v in best_params.items() if not isinstance(v, list)}\n",
    "\n",
    "    best_params_grid = {**str_params_grid, **int_params_grid, **int_grid}\n",
    "    # best_params_grid['tfidf__max_features'] = [1000]\n",
    "\n",
    "    print('DEBUG: params after transform: ', best_params_grid)\n",
    "\n",
    "    # Creamos el objeto GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=best_params_grid, cv=5, verbose=2)\n",
    "\n",
    "    # Ajustamos el modelo a los datos de entrenamiento\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Obtenemos los mejores parámetros\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f'Resultados segunda búsqueda: {best_params}', '\\n')\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def train_final_model(model_name, classifier, X_train, y_train) -> list:\n",
    "\n",
    "    print(' Creando modelo final con los mejores parámetros '.center(80, '#'))\n",
    "    \n",
    "    # Creacion del pipeline modelo final\n",
    "    final_model = Pipeline(steps=[\n",
    "        ## Se aplica el modelo\n",
    "        (model_name, classifier)\n",
    "    ])\n",
    "\n",
    "    # Ajuste del modelo\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    # Medimos el accuracy del modelo\n",
    "    accuracy = final_model.score(X_test, y_test)\n",
    "    print(f'Accuracy de {model_name}: {accuracy:,.2%}')\n",
    "\n",
    "    # Se predicen las clases para test\n",
    "    y_pred = final_model.predict(X_test)\n",
    "\n",
    "    p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    return [model_name, accuracy, p, r, f1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..........................LogisticRegression__C=0.1; total time=  29.0s\n",
      "[CV] END ..........................LogisticRegression__C=0.1; total time=  25.0s\n",
      "[CV] END ..........................LogisticRegression__C=0.1; total time=  26.8s\n",
      "[CV] END ..........................LogisticRegression__C=0.1; total time=  25.1s\n",
      "[CV] END ..........................LogisticRegression__C=0.1; total time=  25.8s\n",
      "[CV] END ............................LogisticRegression__C=1; total time=  52.7s\n",
      "[CV] END ............................LogisticRegression__C=1; total time=  44.0s\n",
      "[CV] END ............................LogisticRegression__C=1; total time=  57.8s\n",
      "[CV] END ............................LogisticRegression__C=1; total time=  49.4s\n",
      "[CV] END ............................LogisticRegression__C=1; total time=  46.0s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time= 1.0min\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  49.7s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  59.9s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  51.0s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  47.0s\n",
      "Resultados primera búsqueda: {'LogisticRegression__C': 10} \n",
      "\n",
      "######################## Segunda búsqueda de parámetros ######################## \n",
      "\n",
      "DEBUG: params after transform:  {'LogisticRegression__C': [9.0, 10, 11.0]}\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..........................LogisticRegression__C=9.0; total time=  48.2s\n",
      "[CV] END ..........................LogisticRegression__C=9.0; total time=  40.1s\n",
      "[CV] END ..........................LogisticRegression__C=9.0; total time=  53.9s\n",
      "[CV] END ..........................LogisticRegression__C=9.0; total time=  46.5s\n",
      "[CV] END ..........................LogisticRegression__C=9.0; total time=  51.0s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  56.7s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  44.2s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  53.6s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  46.0s\n",
      "[CV] END ...........................LogisticRegression__C=10; total time=  45.8s\n",
      "[CV] END .........................LogisticRegression__C=11.0; total time=  53.0s\n",
      "[CV] END .........................LogisticRegression__C=11.0; total time=  50.8s\n",
      "[CV] END .........................LogisticRegression__C=11.0; total time=  49.4s\n",
      "[CV] END .........................LogisticRegression__C=11.0; total time=  51.7s\n",
      "[CV] END .........................LogisticRegression__C=11.0; total time=  50.6s\n",
      "Resultados segunda búsqueda: {'LogisticRegression__C': 11.0} \n",
      "\n",
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de LogisticRegression: 88.80%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = LogisticRegression()\n",
    "model_name = 'LogisticRegression'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    \n",
    "    f'{model_name}__C': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "\n",
    "best_classifier = LogisticRegression(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de LogisticRegression: 92.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0860770\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'C': 11,\n",
    "}\n",
    "model_name = 'LogisticRegression'\n",
    "best_classifier = LogisticRegression(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.5s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END ................................NaiveBayes__alpha=1; total time=   0.4s\n",
      "[CV] END ................................NaiveBayes__alpha=1; total time=   0.4s\n",
      "[CV] END ................................NaiveBayes__alpha=1; total time=   0.4s\n",
      "[CV] END ................................NaiveBayes__alpha=1; total time=   0.4s\n",
      "[CV] END ................................NaiveBayes__alpha=1; total time=   0.4s\n",
      "[CV] END ...............................NaiveBayes__alpha=10; total time=   0.4s\n",
      "[CV] END ...............................NaiveBayes__alpha=10; total time=   0.5s\n",
      "[CV] END ...............................NaiveBayes__alpha=10; total time=   0.4s\n",
      "[CV] END ...............................NaiveBayes__alpha=10; total time=   0.5s\n",
      "[CV] END ...............................NaiveBayes__alpha=10; total time=   0.4s\n",
      "Resultados primera búsqueda: {'NaiveBayes__alpha': 0.1} \n",
      "\n",
      "######################## Segunda búsqueda de parámetros ######################## \n",
      "\n",
      "DEBUG: params after transform:  {'NaiveBayes__alpha': [0.09000000000000001, 0.1, 0.11]}\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END ..............NaiveBayes__alpha=0.09000000000000001; total time=   0.5s\n",
      "[CV] END ..............NaiveBayes__alpha=0.09000000000000001; total time=   0.4s\n",
      "[CV] END ..............NaiveBayes__alpha=0.09000000000000001; total time=   0.4s\n",
      "[CV] END ..............NaiveBayes__alpha=0.09000000000000001; total time=   0.5s\n",
      "[CV] END ..............NaiveBayes__alpha=0.09000000000000001; total time=   0.6s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.5s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END ..............................NaiveBayes__alpha=0.1; total time=   0.4s\n",
      "[CV] END .............................NaiveBayes__alpha=0.11; total time=   0.4s\n",
      "[CV] END .............................NaiveBayes__alpha=0.11; total time=   0.4s\n",
      "[CV] END .............................NaiveBayes__alpha=0.11; total time=   0.4s\n",
      "[CV] END .............................NaiveBayes__alpha=0.11; total time=   0.4s\n",
      "[CV] END .............................NaiveBayes__alpha=0.11; total time=   0.5s\n",
      "Resultados segunda búsqueda: {'NaiveBayes__alpha': 0.09000000000000001} \n",
      "\n",
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de NaiveBayes: 78.30%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = MultinomialNB()\n",
    "model_name = 'NaiveBayes'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    \n",
    "    f'{model_name}__alpha': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "\n",
    "best_classifier = MultinomialNB(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de NaiveBayes: 78.76%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'alpha': 0.9,\n",
    "}\n",
    "model_name = 'NaiveBayes'\n",
    "best_classifier = MultinomialNB(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.8min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.8min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=5; total time= 1.9min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=5; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=5; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=5; total time= 1.8min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=5; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=5; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=5; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=5; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=5; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=manhattan, KNeighbors__n_neighbors=5; total time= 2.2min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=3; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=3; total time= 2.1min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=3; total time= 1.8min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=3; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=5; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=5; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=5; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=5; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=cosine, KNeighbors__n_neighbors=5; total time= 2.1min\n",
      "Resultados primera búsqueda: {'KNeighbors__metric': 'euclidean', 'KNeighbors__n_neighbors': 3} \n",
      "\n",
      "######################## Segunda búsqueda de parámetros ######################## \n",
      "\n",
      "DEBUG: params after transform:  {'KNeighbors__metric': ['euclidean'], 'KNeighbors__n_neighbors': [3, 4]}\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 2.1min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 2.1min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 2.0min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=3; total time= 1.6min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=4; total time= 1.7min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=4; total time= 2.1min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=4; total time= 2.2min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=4; total time= 2.3min\n",
      "[CV] END KNeighbors__metric=euclidean, KNeighbors__n_neighbors=4; total time= 2.2min\n",
      "Resultados segunda búsqueda: {'KNeighbors__metric': 'euclidean', 'KNeighbors__n_neighbors': 3} \n",
      "\n",
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de KNeighbors: 67.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = KNeighborsClassifier()\n",
    "model_name = 'KNeighbors'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    \n",
    "    f'{model_name}__n_neighbors': [3, 5],\n",
    "    f'{model_name}__metric': ['euclidean', 'manhattan', 'cosine']\n",
    "}\n",
    "\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "best_classifier = KNeighborsClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'metric': 'euclidean',\n",
    "    'n_neighbors': 3\n",
    "}\n",
    "model_name = 'KNeighbors'\n",
    "best_classifier = KNeighborsClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Arboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  11.7s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  12.0s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  11.2s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  11.2s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  11.0s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  11.1s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  12.3s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  10.9s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  11.9s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  11.2s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  11.0s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  11.3s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  11.9s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  11.3s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  11.4s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  11.2s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  10.8s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  11.2s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  11.4s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  11.0s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  22.5s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  23.0s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  22.4s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  23.0s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  23.5s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  23.1s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  23.4s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  23.7s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  23.3s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  23.5s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  22.7s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  23.0s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  22.9s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  23.8s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  23.2s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  25.2s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  22.5s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  22.7s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  23.7s\n",
      "[CV] END DecisionTree__criterion=gini, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  23.1s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  31.4s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  31.4s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  36.2s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  29.8s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time=  27.5s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  27.6s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  27.5s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  28.4s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  28.1s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time=  29.4s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  28.3s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  28.6s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  28.7s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  27.9s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time=  28.0s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  28.8s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  27.2s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  27.5s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  34.0s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=5, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time=  36.9s\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time= 1.6min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=10; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=10; total time= 1.4min\n",
      "Resultados primera búsqueda: {'DecisionTree__criterion': 'entropy', 'DecisionTree__max_depth': 10, 'DecisionTree__min_samples_leaf': 2, 'DecisionTree__min_samples_split': 5} \n",
      "\n",
      "######################## Segunda búsqueda de parámetros ######################## \n",
      "\n",
      "DEBUG: params after transform:  {'DecisionTree__criterion': ['entropy'], 'DecisionTree__max_depth': [10, 11], 'DecisionTree__min_samples_leaf': [2, 3], 'DecisionTree__min_samples_split': [5, 6]}\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.0min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.0min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.0min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.1min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.1min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.0min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.0min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.1min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.5min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.4min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=10, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=5; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=2, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=5; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.3min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "[CV] END DecisionTree__criterion=entropy, DecisionTree__max_depth=11, DecisionTree__min_samples_leaf=3, DecisionTree__min_samples_split=6; total time= 1.2min\n",
      "Resultados segunda búsqueda: {'DecisionTree__criterion': 'entropy', 'DecisionTree__max_depth': 11, 'DecisionTree__min_samples_leaf': 2, 'DecisionTree__min_samples_split': 6} \n",
      "\n",
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de DecisionTree: 18.70%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = DecisionTreeClassifier()\n",
    "model_name = 'DecisionTree'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    \n",
    "    f'{model_name}__criterion': ['gini', 'entropy'],\n",
    "    f'{model_name}__max_depth': [5, 10],\n",
    "    f'{model_name}__min_samples_split': [5, 10],\n",
    "    f'{model_name}__min_samples_leaf': [2, 3]\n",
    "}\n",
    "\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "\n",
    "best_classifier = DecisionTreeClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de DecisionTree: 18.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'criterion': 'entropy',\n",
    "    'max_depth': 11,\n",
    "    'min_samples_leaf': 2\n",
    "}\n",
    "model_name = 'DecisionTree'\n",
    "best_classifier = DecisionTreeClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZ2bV7Ov2LMH",
    "outputId": "a3efa483-4b96-4629-f6ba-2328a2370fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV] END .......SVC__C=1, SVC__gamma=0.1, SVC__kernel=linear; total time=13.9min\n",
      "[CV] END .......SVC__C=1, SVC__gamma=0.1, SVC__kernel=linear; total time=14.7min\n",
      "[CV] END ..........SVC__C=1, SVC__gamma=0.1, SVC__kernel=rbf; total time=32.6min\n",
      "[CV] END ..........SVC__C=1, SVC__gamma=0.1, SVC__kernel=rbf; total time=33.7min\n",
      "[CV] END .........SVC__C=1, SVC__gamma=1, SVC__kernel=linear; total time=13.7min\n",
      "[CV] END .........SVC__C=1, SVC__gamma=1, SVC__kernel=linear; total time=14.8min\n",
      "[CV] END ............SVC__C=1, SVC__gamma=1, SVC__kernel=rbf; total time=16.9min\n",
      "[CV] END ............SVC__C=1, SVC__gamma=1, SVC__kernel=rbf; total time=18.1min\n",
      "[CV] END ......SVC__C=10, SVC__gamma=0.1, SVC__kernel=linear; total time=10.2min\n",
      "[CV] END ......SVC__C=10, SVC__gamma=0.1, SVC__kernel=linear; total time=11.1min\n",
      "[CV] END .........SVC__C=10, SVC__gamma=0.1, SVC__kernel=rbf; total time=12.2min\n",
      "[CV] END .........SVC__C=10, SVC__gamma=0.1, SVC__kernel=rbf; total time=13.3min\n",
      "[CV] END ........SVC__C=10, SVC__gamma=1, SVC__kernel=linear; total time=10.3min\n",
      "[CV] END ........SVC__C=10, SVC__gamma=1, SVC__kernel=linear; total time=11.1min\n",
      "[CV] END ...........SVC__C=10, SVC__gamma=1, SVC__kernel=rbf; total time=13.9min\n",
      "[CV] END ...........SVC__C=10, SVC__gamma=1, SVC__kernel=rbf; total time=15.1min\n",
      "Resultados primera búsqueda: {'SVC__C': 10, 'SVC__gamma': 1, 'SVC__kernel': 'rbf'} \n",
      "\n",
      "######################## Segunda búsqueda de parámetros ######################## \n",
      "\n",
      "DEBUG: params after transform:  {'SVC__C': [9.0, 10, 11.0], 'SVC__gamma': [0.9, 1, 1.1], 'SVC__kernel': ['rbf']}\n",
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV] END ........SVC__C=9.0, SVC__gamma=0.9, SVC__kernel=rbf; total time=13.6min\n",
      "[CV] END ........SVC__C=9.0, SVC__gamma=0.9, SVC__kernel=rbf; total time=14.7min\n",
      "[CV] END ..........SVC__C=9.0, SVC__gamma=1, SVC__kernel=rbf; total time=13.8min\n",
      "[CV] END ..........SVC__C=9.0, SVC__gamma=1, SVC__kernel=rbf; total time=15.0min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = SVC()\n",
    "model_name = 'SVC'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "\n",
    "    f'{model_name}__C': [1, 10],\n",
    "    f'{model_name}__kernel': ['linear', 'rbf'],\n",
    "    f'{model_name}__gamma': [0.1, 1]\n",
    "}\n",
    "\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "\n",
    "best_classifier = SVC(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de SVC: 84.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0860770\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'C': 10,\n",
    "    'gamma': 1, \n",
    "    'kernel': 'rbf'\n",
    "    }\n",
    "model_name = 'SVC'\n",
    "best_classifier = SVC(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74hmGKsU2LMI",
    "outputId": "9c2e4444-9770-4f38-de32-f1beff52fbb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  10.0s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=   9.8s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  18.5s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  19.2s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  10.0s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  10.6s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  18.9s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  19.6s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=   9.4s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  10.4s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  18.4s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  20.0s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=   8.6s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  10.1s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  18.2s\n",
      "[CV] END RandomForest__max_depth=5, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  19.7s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  22.6s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  23.5s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  45.4s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  47.1s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  23.1s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  23.7s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  45.8s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  47.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  21.8s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=100; total time=  23.3s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  44.9s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  46.3s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  22.1s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=100; total time=  23.7s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  44.4s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=4, RandomForest__min_samples_split=5, RandomForest__n_estimators=200; total time=  46.4s\n",
      "Resultados primera búsqueda: {'RandomForest__max_depth': 10, 'RandomForest__min_samples_leaf': 2, 'RandomForest__min_samples_split': 2, 'RandomForest__n_estimators': 200} \n",
      "\n",
      "######################## Segunda búsqueda de parámetros ######################## \n",
      "\n",
      "DEBUG: params after transform:  {'RandomForest__max_depth': [9, 10, 11], 'RandomForest__min_samples_leaf': [1, 2, 3], 'RandomForest__min_samples_split': [1, 2, 3], 'RandomForest__n_estimators': [180.0, 200, 220.0]}\n",
      "Fitting 2 folds for each of 81 candidates, totalling 162 fits\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  39.5s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  40.3s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  41.6s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  41.7s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  38.5s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  40.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  39.2s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  38.6s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  39.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  39.9s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  39.5s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  40.5s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=9, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  46.2s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  47.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  46.1s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  46.4s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  48.3s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  47.1s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  46.1s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  47.3s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  44.7s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  45.8s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  45.9s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  45.7s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=10, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  53.9s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  55.3s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  53.4s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  54.3s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=1, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  52.5s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  54.2s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  54.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  54.4s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=2, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=200; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=1, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  53.1s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=200; total time=  54.7s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=2, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=180.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  53.5s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=200; total time=  53.2s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n",
      "[CV] END RandomForest__max_depth=11, RandomForest__min_samples_leaf=3, RandomForest__min_samples_split=3, RandomForest__n_estimators=220.0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "126 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of RandomForestClassifier must be an int in the range [1, inf). Got 180.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of RandomForestClassifier must be an int in the range [1, inf). Got 220.0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.90786585        nan\n",
      "        nan 0.90600532        nan        nan        nan        nan\n",
      "        nan 0.89548337        nan        nan 0.89647565        nan\n",
      "        nan        nan        nan        nan 0.88246007        nan\n",
      "        nan 0.88740073        nan        nan        nan        nan\n",
      "        nan 0.93263068        nan        nan 0.93312679        nan\n",
      "        nan        nan        nan        nan 0.92372106        nan\n",
      "        nan 0.92390713        nan        nan        nan        nan\n",
      "        nan 0.9135919         nan        nan 0.91394323        nan\n",
      "        nan        nan        nan        nan 0.95158675        nan\n",
      "        nan 0.94817589        nan        nan        nan        nan\n",
      "        nan 0.94098212        nan        nan 0.94232578        nan\n",
      "        nan        nan        nan        nan 0.93403634        nan\n",
      "        nan 0.9300673         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados segunda búsqueda: {'RandomForest__max_depth': 11, 'RandomForest__min_samples_leaf': 1, 'RandomForest__min_samples_split': 2, 'RandomForest__n_estimators': 200} \n",
      "\n",
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de RandomForest: 57.40%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = RandomForestClassifier()\n",
    "model_name = 'RandomForest'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "\n",
    "    f'{model_name}__n_estimators': [100, 200],\n",
    "    f'{model_name}__max_depth': [5, 10],\n",
    "    f'{model_name}__min_samples_split': [2, 5],\n",
    "    f'{model_name}__min_samples_leaf': [2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "\n",
    "best_classifier = RandomForestClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de RandomForest: 55.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 11,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1\n",
    "}\n",
    "model_name = 'RandomForest'\n",
    "best_classifier = RandomForestClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 MLP Classifier (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 4.5min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 4.4min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 4.9min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 4.1min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 4.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time=10.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 9.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 9.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 9.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 9.6min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 3.9min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 3.6min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 4.2min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 3.7min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 9.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 9.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time=10.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 9.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 9.8min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 2.5min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 2.7min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 2.5min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 2.4min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 6.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 6.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 6.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 6.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time= 6.2min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 3.1min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 2.6min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 2.9min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 2.5min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 8.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 6.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.001, MLP__hidden_layer_sizes=(50, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 7.2min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 9.4min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 6.9min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 5.5min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 6.4min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=adam; total time= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time=10.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time=10.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time=10.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time=10.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=constant, MLP__solver=sgd; total time=10.2min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 7.2min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 7.7min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 5.8min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 7.0min\n",
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=adam; total time= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ccsar\\miniconda3\\envs\\env_nlp\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END MLP__activation=relu, MLP__alpha=0.01, MLP__hidden_layer_sizes=(100, 50), MLP__learning_rate=adaptive, MLP__solver=sgd; total time= 9.9min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = MLPClassifier()\n",
    "model_name = 'MLP'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "    \n",
    "    f'{model_name}__hidden_layer_sizes': [(100, 50), (50, 50)],\n",
    "    f'{model_name}__activation': ['relu', 'tanh'],\n",
    "    f'{model_name}__solver': ['adam', 'sgd'],\n",
    "    f'{model_name}__alpha': [0.001, 0.01],\n",
    "    f'{model_name}__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "\n",
    "best_classifier = MLPClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n",
      "Accuracy de MLP: 69.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A0860770\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'hidden_layer_sizes': (50, 50),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'sgd',\n",
    "    'alpha': 0.001,\n",
    "    'learning_rate': 'constant'\n",
    "}\n",
    "model_name = 'MLP'\n",
    "best_classifier = MLPClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NX9VGUkq2LML",
    "outputId": "76fc76ab-7388-4586-d1f9-9c53fa9f96ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## Primera búsqueda de parámetros ########################\n",
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.1s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=0.8, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.1, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=3, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=0.8; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n",
      "[CV] END XGB__colsample_bytree=1.0, XGB__learning_rate=0.3, XGB__max_depth=5, XGB__subsample=1.0; total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 32 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n32 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44], got [ 1  2  3  4  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n 27 28 29 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 50]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-13-866907a39f73>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     14\u001b[0m }\n",
      "\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cv_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel_best_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'tfidf'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m<ipython-input-11-3ceb9d510839>\u001b[0m in \u001b[0;36mtrain_cv_models\u001b[0;34m(model_name, classifier, param_grid, X_train, y_train)\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Ajustamos el modelo a los datos de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Obtenemos los mejores parámetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1471\u001b[0m                 )\n",
      "\u001b[1;32m   1472\u001b[0m             ):\n",
      "\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n",
      "\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[1;32m    994\u001b[0m                     )\n",
      "\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    998\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n",
      "\u001b[1;32m    527\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    528\u001b[0m             )\n",
      "\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: \n",
      "All the 32 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "32 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py\", line 333, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1491, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44], got [ 1  2  3  4  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 50]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Definimos el modelo a usar\n",
    "classifier = xgb.XGBClassifier()\n",
    "model_name = 'XGB'\n",
    "\n",
    "# Definimos los parámetros a explorar\n",
    "param_grid = {\n",
    "\n",
    "    f'{model_name}__max_depth': [3, 5],\n",
    "    f'{model_name}__learning_rate': [0.1, 0.3],\n",
    "    f'{model_name}__subsample': [0.8, 1.0],\n",
    "    f'{model_name}__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "best_params = train_cv_models(model_name, classifier, param_grid, X_train, y_train)\n",
    "model_best_params = {k.split('__')[1]:v for k,v in best_params.items() if 'tfidf' not in k}\n",
    "\n",
    "best_classifier = xgb.XGBClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Creando modelo final con los mejores parámetros ################\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44], got [ 1  2  3  4  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n 27 28 29 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mXGB\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     11\u001b[0m best_classifier \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_best_params)\n\u001b[1;32m---> 12\u001b[0m model_stats \u001b[39m=\u001b[39m train_final_model(model_name, best_classifier, X_train, y_train)\n\u001b[0;32m     13\u001b[0m results\u001b[39m.\u001b[39mappend(model_stats)\n",
      "Cell \u001b[1;32mIn[10], line 69\u001b[0m, in \u001b[0;36mtrain_final_model\u001b[1;34m(model_name, classifier, X_train, y_train)\u001b[0m\n\u001b[0;32m     63\u001b[0m final_model \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[\n\u001b[0;32m     64\u001b[0m     \u001b[39m## Se aplica el modelo\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     (model_name, classifier)\n\u001b[0;32m     66\u001b[0m ])\n\u001b[0;32m     68\u001b[0m \u001b[39m# Ajuste del modelo\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m final_model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     71\u001b[0m \u001b[39m# Medimos el accuracy del modelo\u001b[39;00m\n\u001b[0;32m     72\u001b[0m accuracy \u001b[39m=\u001b[39m final_model\u001b[39m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\imblearn\\pipeline.py:297\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    296\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 297\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, yt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     expected_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m   1487\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1488\u001b[0m     classes\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1489\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (classes \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1490\u001b[0m ):\n\u001b[1;32m-> 1491\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1492\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1493\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00mclasses\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1494\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44], got [ 1  2  3  4  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n 27 28 29 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 48 50]"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Definimos los mejores parámetros encontrados\n",
    "model_best_params = {\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "model_name = 'XGB'\n",
    "best_classifier = xgb.XGBClassifier(**model_best_params)\n",
    "model_stats = train_final_model(model_name, best_classifier, X_train, y_train)\n",
    "results.append(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.883943</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.880762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.796886</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.780723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.682722</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.673619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.243629</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.202258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>0.860776</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>0.835338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.625686</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.548560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.712400</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.700487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision  Recall  F1_score\n",
       "0  LogisticRegression    0.8825   0.883943  0.8825  0.880762\n",
       "1          NaiveBayes    0.7795   0.796886  0.7795  0.780723\n",
       "2          KNeighbors    0.6740   0.682722  0.6740  0.673619\n",
       "3        DecisionTree    0.1885   0.243629  0.1885  0.202258\n",
       "4                 SVC    0.8425   0.860776  0.8425  0.835338\n",
       "5        RandomForest    0.5570   0.625686  0.5570  0.548560\n",
       "6                 MLP    0.6975   0.712400  0.6975  0.700487"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import winsound\n",
    "[winsound.Beep(400, 500) for i in range(3)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
